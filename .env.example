# ------------------------------------------------------------
# LangChain Qdrant API Server - Environment Example
# ------------------------------------------------------------
# Copy this file to `.env` and fill in the values.
# Never commit real API keys or passwords to git.
# ------------------------------------------------------------

# -------------------------
# API & Server
# -------------------------
# API key for your FastAPI endpoints (required)
API_KEY=your_api_key_here

# Port the FastAPI server listens on
API_PORT=8000

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# -------------------------
# Qdrant Vector Database
# -------------------------
# URL of your Qdrant instance (internal or cloud)
QDRANT_URL=http://qdrant:6333

# Optional API key for secured Qdrant instances
QDRANT_API_KEY=your_qdrant_api_key_here

# Default size of embedding vectors (must match your embedding model)
VECTOR_SIZE=1536

# TTL for collection cache in seconds
COLLECTION_CACHE_TTL=10

# Default collection name used for ingests/queries
DEFAULT_COLLECTION=knowledge

# Number of top results returned for each query
QUERY_TOP_K=5

# -------------------------
# Ollama Server (LLM & Embeddings)
# -------------------------
# Base URL of Ollama server
OLLAMA_BASE_URL=http://ollama:11434

# Name of embedding model
EMBED_MODEL=nomic-embed-text

# Name of LLM model
LLM_MODEL=llama3:8b

# Maximum context length for LLM
LLM_CTX=16384

# Maximum number of tokens per generation
LLM_MAX_TOKENS=300

# Enable streaming mode for LLM responses (true/false)
LLM_STREAM=false

# Retry settings for Ollama API calls
OLLAMA_RETRY_COUNT=3
OLLAMA_RETRY_DELAY=2.0  # seconds

# -------------------------
# PostgreSQL Database
# -------------------------
DB_HOST=your_db_host         # e.g., localhost or remote host
DB_PORT=5432
DB_NAME=your_db_name
DB_USER=your_db_user
DB_PASSWORD=your_db_password

# -------------------------
# Ingestion Tuning
# -------------------------
# Text chunk size for embedding
CHUNK_SIZE=800

# Overlap between consecutive chunks
CHUNK_OVERLAP=120

# Batch size for embedding requests
EMBED_BATCH_SIZE=64

# Number of log lines to keep per chunk
LOG_LINES_PER_CHUNK=80

# -------------------------
# Notes
# -------------------------
# 1. Replace all placeholder values with your real credentials.
# 2. Ensure VECTOR_SIZE matches the output size of your embedding model.
# 3. Adjust CHUNK_SIZE, CHUNK_OVERLAP, and QUERY_TOP_K for optimal performance.
# 4. Keep sensitive info like API keys and DB passwords secret!
